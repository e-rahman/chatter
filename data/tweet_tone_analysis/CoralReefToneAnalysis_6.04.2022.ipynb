{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from pandas import json_normalize\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, CategoriesOptions, ConceptsOptions, EmotionOptions, EntitiesOptions, KeywordsOptions, RelationsOptions, SemanticRolesOptions\n",
    "from dotenv import load_dotenv\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to IBM API\n",
    "nlu_apikey = \"insert here\"\n",
    "nlu_url = \"insert here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @IndoPacScarini: Did u know cyanobacteria u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0\n",
       "0           0  RT @IndoPacScarini: Did u know cyanobacteria u..."
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset \n",
    "dataset = pd.read_csv('/Users/erahm/chatter/front-end/src/CoralReef.csv')\n",
    "#dataset.columns = [\"Message\"]\n",
    "dataset.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @IndoPacScarini: Did u know cyanobacteria u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0\n",
       "0           0  RT @IndoPacScarini: Did u know cyanobacteria u..."
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any duplicate messages\n",
    "updated_df = dataset.drop_duplicates(keep='last')\n",
    "updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset as string\n",
    "dataset_string = updated_df.to_string()\n",
    "dataset_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Data Cleaning\n",
    "    \n",
    "    # Convert everything to lowercase\n",
    "    dataset_string = dataset_string.lower() \n",
    "    \n",
    "    # Remove mentions   \n",
    "    dataset_string = re.sub('@','', dataset_string)  \n",
    "    \n",
    "    # Remove urls\n",
    "    #dataset_string = re.sub(r'https?:\\/\\/.*\\/\\w*', '', dataset_string)\n",
    "    \n",
    "    # Remove hashtags\n",
    "    dataset_string = re.sub(r'#\\w*', '', dataset_string)    \n",
    "    \n",
    "    # Remove numbers\n",
    "    dataset_string = re.sub(r'\\d+', '', dataset_string)  \n",
    "    \n",
    "    # Remove punctuation\n",
    "    #dataset_string = re.sub(r\"[;':@#?!\\&/$]+ *\", ' ', dataset_string)\n",
    "    \n",
    "    # Remove that funny diamond\n",
    "    dataset_string = re.sub(r\"U+FFFD \", ' ', dataset_string)\n",
    "\n",
    "    # Remove 'rt' denoting start of new message\n",
    "    dataset_string = re.sub(r\"rt \", ' ', dataset_string)\n",
    "\n",
    "    # Print updated string\n",
    "    dataset_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweet Tone Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tone Analyser Client\n",
    "\n",
    "# Create authentication object\n",
    "authenticator = IAMAuthenticator(nlu_apikey)\n",
    "\n",
    "# Create tone_analyzer instance\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1 (\n",
    "    version=\"2017-09-21\",\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "# Set the service endpoint\n",
    "natural_language_understanding.set_service_url(nlu_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"usage\": {\n",
      "    \"text_units\": 4,\n",
      "    \"text_characters\": 33618,\n",
      "    \"features\": 1\n",
      "  },\n",
      "  \"language\": \"en\",\n",
      "  \"emotion\": {\n",
      "    \"targets\": [\n",
      "      {\n",
      "        \"text\": \"coral\",\n",
      "        \"emotion\": {\n",
      "          \"sadness\": 0.130359,\n",
      "          \"joy\": 0.455424,\n",
      "          \"fear\": 0.106911,\n",
      "          \"disgust\": 0.011906,\n",
      "          \"anger\": 0.019639\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"text\": \"coral reef\",\n",
      "        \"emotion\": {\n",
      "          \"sadness\": 0.128174,\n",
      "          \"joy\": 0.457788,\n",
      "          \"fear\": 0.102401,\n",
      "          \"disgust\": 0.010972,\n",
      "          \"anger\": 0.019684\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"document\": {\n",
      "      \"emotion\": {\n",
      "        \"sadness\": 0.154923,\n",
      "        \"joy\": 0.396473,\n",
      "        \"fear\": 0.103936,\n",
      "        \"disgust\": 0.014794,\n",
      "        \"anger\": 0.027123\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Emotional Tone Analysis\n",
    "response = natural_language_understanding.analyze(\n",
    "    text=dataset_string,\n",
    "    features=Features(emotion=EmotionOptions(targets=['coral', 'coral reef']))).get_result()\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.005, 'neu': 0.947, 'pos': 0.048, 'compound': 0.9983}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(dataset_string)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a4ba6dd97509981000777d75f40228883b2b5fada7e202bb5d5e077c53e542c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
